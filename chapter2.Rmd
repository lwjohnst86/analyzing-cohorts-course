```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
load("datasets/framingham.rda")
load("datasets/nickel.rda")
load("datasets/dietchd.rda")
```

# Chapter 2: Data exploring, wrangling, and formatting

- Look over data to find problems or fit to needs of research question
- Wrangling data to get into proper for statistics
- Transforming for statistics if necessary

**Objectives**

- How to get data into form for quick exploration
- How to wrangle the data to get into a form to use for the analysis/statistic
- Know the various tools to transform the data and when is more appropriate to
use them
    - Know to be very careful of ever converting continuous into discrete
    - Know when and why to transform variables (good reasons and bad)
    - Reducing number of categories in categorical variable
- Dealing with outliers (or not)

**Lessons to achieve objectives:**

- Exploring data (dot/boxplots, violinplots, correlation heatmap)
    - Need to understand the data before doing any serious wrangling
- Longitudinal data in wide format
    - converting into long for use by statistical techniques (e.g. mixed effects)
    - talk about tidy data
- Types of transformations and why to use them:
    - Log: if data is highly skewed, if interested in output after
    backtransforming of percent impact rather than on original unit impact
    (often used)
    - square: ... (rarely done)
    - scaled: Put variables on same scale/unit (all become SD, fairly common)
    - Transformation can be used to correct "violations in regression
    assumptions", but this is not often important or necessary.
    - Use transformations such as log if the variable is unitless, or there is
    disagreement between studies on the specific unit, or if the unit value
    varies between studies. That way the result is interpreted in a way that 
    can be compared to previous and future studies.
    - Don't convert continuous to discrete. There could be non-linear relationships
- Categorical variable modication:
    - sometimes some categories are too small, so sometimes for model
    interpretation and generalizability, grouping categories makes sense,
    and to also balance the sample between groups.


**Exercises to reinforce learning:**

- NE: Here's a research question and a dataset. transform the data to be able to 
get the results to be interpreted this specific way.
- MCQ/text: Which transformation is best suited for the research question.

### Exercise: Wide to long for longitudinal data

TODO: I'll need to wrangle one of the datasets to fit this form for this exercise.
Some cohort studies do this, but many don't. Still important to know how to do.

```{r}
dataname %>% 
    gather(Measure, Value, -SubjectID) %>%
    print() %>% # to show what it looks like
    separate("Measure", into = c("Measure", "Time"), sep = "_") %>%  
    # _ is one of many separations.
    print() %>% # show what it looks like
    spread(Measure, Value)
    
```


### Exercise: Reduce number of categories in these datasets

```{r}
library(forcats)
fh_educ <- framingham %>% 
    mutate(educ_reduced = fct_recode(
        educ, 
        "Post-Secondary" = "College",
        "Post-Secondary" = "Vocational"
        ))

fct_count(fh_educ$educ_reduced)
# TODO: Add another dataset to reduce categories e.g. PROMISE and ethnicity
```


### Exercise: Comparison between different log transformations

```{r}
# TODO: show a cohort with continuous outcome, and log that
fh_transformed <- framingham %>% 
    mutate(scale_bmi = scale(bmi),
           log_bmi = log(bmi))

fh_transformed %>% 
    select(contains("bmi")) %>% 
    gather(bmi_variable, bmi_value) %>% 
    ggplot(aes(x = bmi_value)) +
    geom_histogram() +
    facet_grid( ~ bmi_variable, scale = "free")
```


### Exercise: Data exploration

NE: Create a box and jitter plot of all the variables of interest, at the baseline visit:

```{r ex_eda}
fh_long <- framingham %>% 
    filter(time == 0) %>% 
    select(cvd, totchol, bmi, age) %>% 
    gather(Variable, Value)
    
fh_long

ggplot(fh_long, aes(x = Value)) +
    geom_histogram() +
    facet_grid(~ Variable, scales = "free")
```

### Exercise

NE: Create a simple visual comparing the outcome with the exposures.

```{r}
framingham %>% 
    select(time, cvd, totchol, age, bmi) %>% 
    gather(Variable, Value, -time, -cvd) %>% 
    mutate(cvd = as.factor(cvd)) %>% 
    ggplot(aes(x = Value, group = cvd, fill = cvd)) +
    geom_density(alpha = 0.6) +
    facet_grid(~ Variable, scales = "free")
```

### Exercise

NE: Create a line plot (or summary line plot if data too big) by individual.

```{r}
framing
```


## Lesson 1: Here's the data ... tidy it up!

### Exercise 1: Which are untidy data?
Identify tidy datasets given the statistical technique/study design
(or which are wrong)

- wrong ones (possibles):
    - wide instead of long for longitudinal study
    - wide instead of long for those with the disease and those without
    - different character strings for same disease (rather than numbers), e.g.
    "t2dm" and "dm" for diabetes status
    - "excel" style of two datasets in one spreadsheet
    - 

### Exercise 2: So then, tidy it up!
NE:

... maybe two waves that need to be combined?

```{r}

```

### Exercise 3: Long vs wide, or which side is which?
NE: Sometimes analyses are more easily done with data all completely in a long
form, either for plotting or for summarizing.

```{r}

```

### Exercise 4: Data could be tidy, but not for analysis

NE: We have a longitudinal cohort that has some variables 


```{r}

```
